# ======================================================================
# There are 5 questions in this test with increasing difficulty from 1-5
# Please note that the weight of the grade for the question is relative
# to its difficulty. So your Category 1 question will score much less
# than your Category 5 question.
# ======================================================================
#
# Basic Datasets question
#
# For this task you will train a classifier for Iris flowers using the Iris dataset
# The final layer in your neural network should look like: tf.keras.layers.Dense(3, activation=tf.nn.softmax)
# The input layer will expect data in the shape (4,)
# We've given you some starter code for preprocessing the data
# You'll need to implement the preprocess function for data.map

# =========== 합격 기준 가이드라인 공유 ============= #
# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #
# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #
# =================================================== #
# 문제명: Category 2 - iris
# val_loss: 0.14
# val_acc: 0.93
# =================================================== #
# =================================================== #
# model1: 0.13457

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
import tensorflow_datasets as tfds

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.callbacks import ModelCheckpoint

train_dataset = tfds.load('iris', split = 'train[:80%]')
valid_dataset = tfds.load('iris', split = 'train[80%:]')

def preprocess(data):
  x = data['features']
  y = data['label']
  y = tf.one_hot(y, 3) # y를 3개의 분류로 원핫인코딩
  return x, y

def solution_model():
  batch_size = 10
  train_data = train_dataset.map(preprocess).batch(batch_size)
  valid_data = valid_dataset.map(preprocess).batch(batch_size)

  model = Sequential([
      Dense(1024, input_shape = (4, )),
      Dense(512, activation = 'relu'),
      Dense(256, activation = 'relu'),
      Dense(128, activation = 'relu'),
      Dense(64, activation = 'relu'),
      Dropout(0.5),
      Dense(32, activation = 'relu'),
      Dense(3, activation = 'softmax')  
  ])
  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])

  checkpoint_path = "my_checkpoint.ckpt"
  checkpoint = ModelCheckpoint(filepath = checkpoint_path, monitor = 'val_loss', verbose = 1, save_weights_only = True, save_best_only = True)

  history = model.fit(train_data, validation_data = (valid_data), verbose = 1, epochs = 20, callbacks = [checkpoint],)
  model.load_weights(checkpoint_path)
  return model


# Note that you'll need to save your model as a .h5 like this
# This .h5 will be uploaded to the testing infrastructure
# and a score will be returned to you
if __name__ == '__main__':
    model = solution_model()
    model.save("iris_model1.h5")
# ======================================================================
# There are 5 questions in this test with increasing difficulty from 1-5
# Please note that the weight of the grade for the question is relative
# to its difficulty. So your Category 1 question will score much less
# than your Category 5 question.
# ======================================================================
#
# Basic Datasets question
#
# For this task you will train a classifier for Iris flowers using the Iris dataset
# The final layer in your neural network should look like: tf.keras.layers.Dense(3, activation=tf.nn.softmax)
# The input layer will expect data in the shape (4,)
# We've given you some starter code for preprocessing the data
# You'll need to implement the preprocess function for data.map

# =========== 합격 기준 가이드라인 공유 ============= #
# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #
# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #
# =================================================== #
# 문제명: Category 2 - iris
# val_loss: 0.14
# val_acc: 0.93
# =================================================== #
# =================================================== #
# model1: 0.12655

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential
import tensorflow_datasets as tfds

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.callbacks import ModelCheckpoint

train_dataset = tfds.load('iris', split = 'train[:80%]')
valid_dataset = tfds.load('iris', split = 'train[80%:]')

def preprocess(data):
  x = data['features']
  y = data['label']
  y = tf.one_hot(y, 3) # y를 3개의 분류로 원핫인코딩
  return x, y

def solution_model():
  batch_size = 10
  train_data = train_dataset.map(preprocess).batch(batch_size)
  valid_data = valid_dataset.map(preprocess).batch(batch_size)

  model = Sequential([
      Dense(1024, input_shape = (4, )),
      Dense(512, activation = 'relu'),
      Dense(256, activation = 'relu'),
      Dense(128, activation = 'relu'),
      Dense(64, activation = 'relu'),
      Dropout(0.5),
      Dense(32, activation = 'relu'),
      Dense(3, activation = 'softmax')  
  ])
  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])

  checkpoint_path = "my_checkpoint.ckpt"
  checkpoint = ModelCheckpoint(filepath = checkpoint_path, monitor = 'val_loss', verbose = 1, save_weights_only = True, save_best_only = True)

  history = model.fit(train_data, validation_data = (valid_data), verbose = 1, epochs = 30, callbacks = [checkpoint],)
  model.load_weights(checkpoint_path)
  return model


# Note that you'll need to save your model as a .h5 like this
# This .h5 will be uploaded to the testing infrastructure
# and a score will be returned to you
if __name__ == '__main__':
    model = solution_model()
    model.save("iris_model2.h5")
