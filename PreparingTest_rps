# ======================================================================
# There are 5 questions in this test with increasing difficulty from 1-5
# Please note that the weight of the grade for the question is relative
# to its difficulty. So your Category 1 question will score much less
# than your Category 5 question.
# ======================================================================
#
# Computer Vision with CNNs
#
# For this task you will build a classifier for Rock-Paper-Scissors 
# based on the rps dataset.
#
# IMPORTANT: Your final layer should be as shown, do not change the
# provided code, or the tests may fail
#
# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth
# So ensure that your input layer is designed accordingly, or the tests
# may fail. 
#
# NOTE THAT THIS IS UNLABELLED DATA. 
# You can use the ImageDataGenerator to automatically label it
# and we have provided some starter code.

# =========== 합격 기준 가이드라인 공유 ============= #
# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #
# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #
# =================================================== #
# 문제명: Category 3 - rps
# val_loss: 0.0871
# val_acc: 0.97
# =================================================== #
# =================================================== #
# model1: 0.08156
import numpy as np
import tensorflow as tf

from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, AveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import urllib.request
import zipfile
from IPython.display import Image



def solution_model():
  url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'
  urllib.request.urlretrieve(url, 'rps.zip')
  local_zip = 'rps.zip'
  zip_ref = zipfile.ZipFile(local_zip, 'r')
  zip_ref.extractall('tmp/')
  zip_ref.close()

  TRAINING_DIR = "tmp/rps/"

  training_datagen = ImageDataGenerator(
    rescale = 1 / 255,
    rotation_range = 5,
    width_shift_range = 0.05,
    height_shift_range = 0.05,
    zoom_range = 0.05,
    horizontal_flip = True,
    fill_mode = 'reflect',
    validation_split = 0.2
  )

# training / validation dataset 만들기
  training_generator = training_datagen.flow_from_directory(
    TRAINING_DIR, batch_size = 128, target_size = (150, 150), class_mode = 'categorical', subset = 'training'
  )

  validation_generator = training_datagen.flow_from_directory(
    TRAINING_DIR, batch_size = 128, target_size = (150, 150), class_mode = 'categorical', subset = 'validation'
  )
  # 모델링
  model = Sequential([
 
    Conv2D(64, (3,3), activation = 'relu', input_shape = (150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    



    # 2D -> 1D로 변환을 위하여 Flatten
    Flatten(),


    # 과적합 방지를 위하여 Dropout을 적용
    Dropout(0.5),

    # Dense
    Dense(512, activation = 'relu'),
    Dense(3, activation = 'softmax')

   

  ])

  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])
  # Model CheckPoint
  file_path = ' "tmp_checkpoint.ckpt"'
  checkpoint = ModelCheckpoint(file_path, monitor = 'val_loss',
                              verbose = 1, save_best_only = True, save_weights_only = True)
  # 학습
  history = model.fit(training_generator, validation_data = validation_generator,
                    verbose = 1, callbacks = [checkpoint], epochs = 25)
  # 학습 완료 후 Load weights
  model.load_weights(file_path)
    
  return model



# Note that you'll need to save your model as a .h5 like this
# This .h5 will be uploaded to the testing infrastructure
# and a score will be returned to you
if __name__ == '__main__':
    model = solution_model()
    model.save("TF3-rps_model1.h5")


# ======================================================================
# There are 5 questions in this test with increasing difficulty from 1-5
# Please note that the weight of the grade for the question is relative
# to its difficulty. So your Category 1 question will score much less
# than your Category 5 question.
# ======================================================================
#
# Computer Vision with CNNs
#
# For this task you will build a classifier for Rock-Paper-Scissors 
# based on the rps dataset.
#
# IMPORTANT: Your final layer should be as shown, do not change the
# provided code, or the tests may fail
#
# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth
# So ensure that your input layer is designed accordingly, or the tests
# may fail. 
#
# NOTE THAT THIS IS UNLABELLED DATA. 
# You can use the ImageDataGenerator to automatically label it
# and we have provided some starter code.

# =========== 합격 기준 가이드라인 공유 ============= #
# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #
# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #
# =================================================== #
# 문제명: Category 3 - rps
# val_loss: 0.0871
# val_acc: 0.97
# =================================================== #
# =================================================== #
# model1: 0.08079
import numpy as np
import tensorflow as tf

from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, AveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import urllib.request
import zipfile
from IPython.display import Image



def solution_model():
  url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'
  urllib.request.urlretrieve(url, 'rps.zip')
  local_zip = 'rps.zip'
  zip_ref = zipfile.ZipFile(local_zip, 'r')
  zip_ref.extractall('tmp/')
  zip_ref.close()

  TRAINING_DIR = "tmp/rps/"

  training_datagen = ImageDataGenerator(
    rescale = 1 / 255,
    rotation_range = 5,
    width_shift_range = 0.05,
    height_shift_range = 0.05,
    zoom_range = 0.05,
    horizontal_flip = True,
    fill_mode = 'reflect',
    validation_split = 0.2
  )

# training / validation dataset 만들기
  training_generator = training_datagen.flow_from_directory(
    TRAINING_DIR, batch_size = 128, target_size = (150, 150), class_mode = 'categorical', subset = 'training'
  )

  validation_generator = training_datagen.flow_from_directory(
    TRAINING_DIR, batch_size = 128, target_size = (150, 150), class_mode = 'categorical', subset = 'validation'
  )
  # 모델링
  model = Sequential([
 
    Conv2D(64, (3,3), activation = 'relu', input_shape = (150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    



    # 2D -> 1D로 변환을 위하여 Flatten
    Flatten(),


    # 과적합 방지를 위하여 Dropout을 적용
    Dropout(0.5),

    # Dense
    Dense(256, activation = 'relu'),
    Dense(32, activation = 'relu'),
    Dense(3, activation = 'softmax')

   

  ])

  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])
  # Model CheckPoint
  file_path = ' "tmp_checkpoint.ckpt"'
  checkpoint = ModelCheckpoint(file_path, monitor = 'val_loss',
                              verbose = 1, save_best_only = True, save_weights_only = True)
  # 학습
  history = model.fit(training_generator, validation_data = validation_generator,
                    verbose = 1, callbacks = [checkpoint], epochs = 25)
  # 학습 완료 후 Load weights
  model.load_weights(file_path)
    
  return model



# Note that you'll need to save your model as a .h5 like this
# This .h5 will be uploaded to the testing infrastructure
# and a score will be returned to you
if __name__ == '__main__':
    model = solution_model()
    model.save("TF3-rps_model2.h5")
